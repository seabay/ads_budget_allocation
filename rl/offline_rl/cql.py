import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from d3rlpy.dataset import MDPDataset
from d3rlpy.algos import CQL

# 1. è¯»å–åŸå§‹æ•°æ®
df = pd.read_csv("offline_ads_data.csv")

# å¹³å°/åœ°åŒºç¦»æ•£ç¼–ç 
platform_ids = df['platform'].astype('category').cat.codes
geo_ids = df['geo'].astype('category').cat.codes
df['platform_id'] = platform_ids
df['geo_id'] = geo_ids

# 2. æ•°å€¼ç‰¹å¾ï¼ˆStandardScalerï¼‰
numeric_features = ['roi_p10', 'roi_p50', 'roi_p90', 'cvr', 'ctr', 'prev_spend']
numeric_data = df[numeric_features].values.astype(np.float32)
scaler = StandardScaler()
scaled_numeric = scaler.fit_transform(numeric_data)

# 3. One-hot ç¼–ç å¹³å°å’Œ geo
platform_onehot = pd.get_dummies(df['platform_id'], prefix='platform')
geo_onehot = pd.get_dummies(df['geo_id'], prefix='geo')

# 4. æ„å»ºæœ€ç»ˆ state å‘é‡
state_df = pd.DataFrame(scaled_numeric, columns=numeric_features)
state_df = pd.concat([state_df, platform_onehot, geo_onehot], axis=1)
states = state_df.values.astype(np.float32)

# 5. åŠ¨ä½œï¼ˆé¢„ç®—ï¼‰å½’ä¸€åŒ–
actions = df['budget'].values.reshape(-1, 1).astype(np.float32)
actions = actions / np.max(actions)

# 6. å¥–åŠ±ï¼ˆROIï¼‰
rewards = df['roi'].values.astype(np.float32)

# 7. æ¯æ¡æ•°æ®çœ‹ä½œå•æ­¥ episodeï¼Œdone=True
terminals = np.ones_like(rewards).astype(bool)

# 8. æ„é€  MDPDataset
dataset = MDPDataset(
    observations=states,
    actions=actions,
    rewards=rewards,
    terminals=terminals
)

# 9. è®­ç»ƒ CQL
cql = CQL(use_gpu=True)
cql.fit(dataset, n_steps=100_000)

# 10. ä¿å­˜æ¨¡å‹
cql.save_model("cql_ads_budget_model.pt")



=====================================================

# ğŸ§ª ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥


# æ¨¡æ‹Ÿä¸€ä¸ªæ–° segment çš„çŠ¶æ€è¾“å…¥
sample_state = np.array([[1.2, 1.5, 1.8, 0.03, 0.12, 10000, 0, 5]])  # æ³¨æ„å¹³å°å’Œ geo è¦æ˜ å°„
sample_state = scaler.transform(sample_state)

# æ¨ç†å»ºè®®çš„ budgetï¼ˆå½’ä¸€åŒ–å€¼ï¼‰
predicted_budget = cql.predict(sample_state)[0][0]
print("Recommended budget (normalized):", predicted_budget)

